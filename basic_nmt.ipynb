{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,LSTM,Bidirectional,Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>À l'aide !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>Saute.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      en          fr\n",
       "0   Run!    Courez !\n",
       "1   Wow!  Ça alors !\n",
       "2  Fire!    Au feu !\n",
       "3  Help!  À l'aide !\n",
       "4  Jump.      Saute."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 10000\n",
    "path = 'fra.txt'\n",
    "df = pd.read_csv(path,sep='\\t', index_col = False)\n",
    "df.columns = ['en','fr']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145435\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en = np.array(df['en'])[:samples]\n",
    "fr = np.array(df['fr'])[:samples]\n",
    "\n",
    "for i in range(len(fr)):\n",
    "     fr[i]= '\\t' + fr[i] + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#char-to-char\n",
    "en_char_set = set()\n",
    "fr_char_set = set()\n",
    "\n",
    "for sent in en:\n",
    "    for char in sent:\n",
    "        en_char_set.add(char)\n",
    "    \n",
    "for sent in fr:\n",
    "    for char in sent:\n",
    "        fr_char_set.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_char = sorted(list(en_char_set))\n",
    "fr_char = sorted(list(fr_char_set))\n",
    "len(fr_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_tokens_len = len(en_char)\n",
    "decoder_tokens_len = len(fr_char)\n",
    "\n",
    "encoder_seq_length = max([len(line) for line in en])\n",
    "decoder_seq_length = max([len(line) for line in fr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_char_idx = dict([(char,i) for i,char in enumerate(en_char)])\n",
    "en_idx_char = dict([(i,char) for i,char in enumerate(en_char)])\n",
    "fr_char_idx = dict([(char,i) for i,char in enumerate(fr_char)])\n",
    "fr_idx_char = dict([(i,char) for i,char in enumerate(fr_char)])\n",
    "\n",
    "fr_char_idx['\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(en),encoder_seq_length,encoder_tokens_len),dtype='float32')\n",
    "decoder_input_data = np.zeros((len(fr),decoder_seq_length,decoder_tokens_len),dtype='float32')\n",
    "decoder_output_data = np.zeros((len(fr),decoder_seq_length,decoder_tokens_len),dtype='float32')\n",
    "\n",
    "for i, (input_text,target_text) in enumerate(zip(en,fr)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,en_char_idx[char]]=1\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,fr_char_idx[char]]=1\n",
    "        if t>0:\n",
    "            decoder_output_data[i,t-1,fr_char_idx[char]]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units = 128\n",
    "epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#char-to-char model\n",
    "encoder_input = Input(shape=(None,encoder_tokens_len))\n",
    "encoder = LSTM(units,return_state=True)\n",
    "encoder_output,state_h,state_c = encoder(encoder_input)\n",
    "\n",
    "encoder_states = [state_h,state_c]\n",
    "\n",
    "decoder_input = Input(shape=(None,decoder_tokens_len))\n",
    "decoder = LSTM(units,return_sequences=True,return_state=True)\n",
    "decoder_output,_,_ = decoder(decoder_input,initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(decoder_tokens_len,activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([encoder_input,decoder_input],decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 92)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 128), (None, 102400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  113152      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 92)     11868       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 227,420\n",
      "Trainable params: 227,420\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3243 - val_loss: 0.4998\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3217 - val_loss: 0.4992\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3206 - val_loss: 0.4985\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3195 - val_loss: 0.5001\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3177 - val_loss: 0.4972\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3169 - val_loss: 0.4977\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3150 - val_loss: 0.4961\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3135 - val_loss: 0.4986\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3123 - val_loss: 0.4963\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3114 - val_loss: 0.4973\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3100 - val_loss: 0.4981\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3088 - val_loss: 0.4971\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3068 - val_loss: 0.4965\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3060 - val_loss: 0.4972\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3051 - val_loss: 0.4985\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3041 - val_loss: 0.4985\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3023 - val_loss: 0.4944\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3005 - val_loss: 0.4952\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2994 - val_loss: 0.4977\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2981 - val_loss: 0.4938\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2974 - val_loss: 0.4973\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2966 - val_loss: 0.4944\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2959 - val_loss: 0.4975\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2933 - val_loss: 0.4929\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2923 - val_loss: 0.4952\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2908 - val_loss: 0.4957\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2894 - val_loss: 0.4985\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2887 - val_loss: 0.4957\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2883 - val_loss: 0.4966\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2863 - val_loss: 0.4956\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2852 - val_loss: 0.4958\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2845 - val_loss: 0.4961\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2833 - val_loss: 0.4960\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2828 - val_loss: 0.4963\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2813 - val_loss: 0.4968\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2793 - val_loss: 0.4989\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2792 - val_loss: 0.5015\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2777 - val_loss: 0.5007\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2772 - val_loss: 0.4955\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2755 - val_loss: 0.5006\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2746 - val_loss: 0.4958\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2736 - val_loss: 0.4986\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2733 - val_loss: 0.4973\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2712 - val_loss: 0.4991\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2700 - val_loss: 0.4968\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2696 - val_loss: 0.4981\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2688 - val_loss: 0.5012\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2678 - val_loss: 0.4997\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2664 - val_loss: 0.4990\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2649 - val_loss: 0.5012\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2645 - val_loss: 0.4992\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2631 - val_loss: 0.5042\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2628 - val_loss: 0.5007\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2612 - val_loss: 0.5022\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2600 - val_loss: 0.5007\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2589 - val_loss: 0.5006\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2584 - val_loss: 0.5037\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2567 - val_loss: 0.5022\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2562 - val_loss: 0.5022\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2555 - val_loss: 0.5064\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2549 - val_loss: 0.5037\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.2541 - val_loss: 0.5068\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 47s 6ms/step - loss: 0.2525 - val_loss: 0.5067\n",
      "Epoch 64/100\n",
      "1024/8000 [==>...........................] - ETA: 37s - loss: 0.2490"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c67341772790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_output_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_model = model.fit([encoder_input_data,decoder_input_data],decoder_output_data,batch_size=batch_size,epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, decoder_tokens_len))\n",
    "    target_seq[0, 0, fr_char_idx['\\t']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_fra_char = fr_idx_char[max_val_index]\n",
    "        translated_sent += sampled_fra_char\n",
    "        \n",
    "        if ( (sampled_fra_char == '\\n') or (len(translated_sent) > decoder_seq_length)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, decoder_tokens_len))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return translated_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Open up.\n",
      "Decoded sentence: Ouvre-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Open up.\n",
      "Decoded sentence: Ouvre-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Perfect!\n",
      "Decoded sentence: Vailui !\n",
      "\n",
      "-\n",
      "Input sentence: See you.\n",
      "Decoded sentence: À plus !\n",
      "\n",
      "-\n",
      "Input sentence: Show me.\n",
      "Decoded sentence: Montre-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Show me.\n",
      "Decoded sentence: Montre-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Shut up!\n",
      "Decoded sentence: Ferme-le !\n",
      "\n",
      "-\n",
      "Input sentence: Shut up!\n",
      "Decoded sentence: Ferme-le !\n",
      "\n",
      "-\n",
      "Input sentence: Shut up!\n",
      "Decoded sentence: Ferme-le !\n",
      "\n",
      "-\n",
      "Input sentence: Shut up!\n",
      "Decoded sentence: Ferme-le !\n",
      "\n",
      "-\n",
      "Input sentence: Shut up!\n",
      "Decoded sentence: Ferme-le !\n",
      "\n",
      "-\n",
      "Input sentence: So long.\n",
      "Decoded sentence: Tais !\n",
      "\n",
      "-\n",
      "Input sentence: Take it.\n",
      "Decoded sentence: Prenez !\n",
      "\n",
      "-\n",
      "Input sentence: Take it.\n",
      "Decoded sentence: Prenez !\n",
      "\n",
      "-\n",
      "Input sentence: Tell me.\n",
      "Decoded sentence: Dis-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Tell me.\n",
      "Decoded sentence: Dis-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Tom won.\n",
      "Decoded sentence: Tom a dichon.\n",
      "\n",
      "-\n",
      "Input sentence: Wake up!\n",
      "Decoded sentence: Réveillez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Wake up!\n",
      "Decoded sentence: Réveillez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Wake up!\n",
      "Decoded sentence: Réveillez-vous !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(150,170):\n",
    "    inp_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', en[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
